#!/usr/bin/env python3
"""
AI Backend Unified Dashboard - Consolidated Version

A single, comprehensive terminal dashboard that combines features from all previous versions:
1. Basic monitoring
2. Lightweight information display
3. Enhanced VRAM monitoring
4. Full service control (Start/Stop/Restart/Enable/Disable)
"""

import asyncio
import json
import subprocess
import threading
import time
from dataclasses import dataclass
from typing import Dict, List, Optional

import psutil
import requests
from textual.app import App, ComposeResult
from textual.binding import Binding
from textual.containers import Container, Horizontal, Vertical, Grid
from textual.reactive import reactive
from textual.widgets import (
    Button,
    Footer,
    Header,
    Label,
    ProgressBar,
    Static,
    DataTable,
)


@dataclass
class ProviderStatus:
    """Represents the status of a provider."""
    name: str
    status: str  # 'active', 'inactive', 'error'
    port: int
    model_count: int
    response_time: float
    vram_usage_mb: float = 0.0
    vram_percentage: float = 0.0
    cpu_usage: float = 0.0
    memory_usage: float = 0.0
    pid: Optional[int] = None


class ProviderMonitor:
    """Handles monitoring of AI backend providers."""

    PROVIDER_ENDPOINTS = {
        "ollama": "http://127.0.0.1:11434/api/tags",
        "llama_cpp_python": "http://127.0.0.1:8000/v1/models",
        "llama_cpp_native": "http://127.0.0.1:8080/v1/models",
        "vllm-qwen": "http://127.0.0.1:8001/v1/models",
        "vllm-dolphin": "http://127.0.0.1:8002/v1/models",
    }

    def check_provider_health(self, name: str, endpoint: str) -> ProviderStatus:
        """Check the health of a provider."""
        start_time = time.time()

        try:
            response = requests.get(endpoint, timeout=3)
            response_time = time.time() - start_time

            if response.status_code == 200:
                try:
                    data = response.json()
                    if "data" in data and isinstance(data["data"], list):
                        model_count = len(data["data"])
                    else:
                        model_count = 0
                except (ValueError, TypeError, KeyError):
                    model_count = 0

                port = int(endpoint.split(":")[2].split("/")[0])

                return ProviderStatus(
                    name=name,
                    status="active",
                    port=port,
                    model_count=model_count,
                    response_time=round(response_time * 1000, 1)
                )
            else:
                return ProviderStatus(
                    name=name,
                    status="error",
                    port=int(endpoint.split(":")[2].split("/")[0]),
                    model_count=0,
                    response_time=0.0
                )
        except requests.exceptions.Timeout:
            return ProviderStatus(
                name=name,
                status="inactive",
                port=int(endpoint.split(":")[2].split("/")[0]),
                model_count=0,
                response_time=3000.0
            )
        except requests.exceptions.ConnectionError:
            return ProviderStatus(
                name=name,
                status="inactive",
                port=int(endpoint.split(":")[2].split("/")[0]),
                model_count=0,
                response_time=0.0
            )
        except Exception:
            return ProviderStatus(
                name=name,
                status="error",
                port=int(endpoint.split(":")[2].split("/")[0]),
                model_count=0,
                response_time=0.0
            )

    def get_all_provider_status(self) -> List[ProviderStatus]:
        """Get status for all providers."""
        return [
            self.check_provider_health(name, endpoint)
            for name, endpoint in self.PROVIDER_ENDPOINTS.items()
        ]

    def systemctl_command(self, command: str, service_name: str) -> bool:
        """Execute a systemctl command."""
        try:
            result = subprocess.run(
                ["systemctl", "--user", command, service_name],
                capture_output=True,
                text=True,
                check=False,
                timeout=10 if command in ["enable", "disable"] else 5
            )
            return result.returncode == 0
        except subprocess.TimeoutExpired:
            return False
        except Exception:
            return False


class GPUMonitor:
    """Monitors GPU resources."""

    def __init__(self):
        self.initialized = False
        try:
            import pynvml
            pynvml.nvmlInit()
            self.initialized = True
            self.device_count = pynvml.nvmlDeviceGetCount()
        except Exception:
            self.initialized = False
            self.device_count = 0

    def get_gpu_info(self):
        """Get information about all GPUs."""
        if not self.initialized:
            return []

        try:
            import pynvml
            gpus = []
            for i in range(self.device_count):
                handle = pynvml.nvmlDeviceGetHandleByIndex(i)
                name = pynvml.nvmlDeviceGetName(handle).decode('utf-8')

                memory_info = pynvml.nvmlDeviceGetMemoryInfo(handle)
                utilization = pynvml.nvmlDeviceGetUtilizationRates(handle)

                gpus.append({
                    'id': i,
                    'name': name,
                    'memory_total_mb': memory_info.total / 1024**2,
                    'memory_used_mb': memory_info.used / 1024**2,
                    'memory_util_percent': (memory_info.used / memory_info.total) * 100 if memory_info.total > 0 else 0,
                    'gpu_util_percent': utilization.gpu,
                })
            return gpus
        except Exception:
            return []


class ProviderCard(Vertical):
    """Interactive card for a single provider."""

    def __init__(self, provider_name: str):
        super().__init__()
        self.provider_name = provider_name
        self.provider_monitor = ProviderMonitor()

    def compose(self) -> ComposeResult:
        # Header with provider name and status
        with Horizontal(classes="card-header"):
            yield Label(self.provider_name, classes="provider-name")
            yield Label("● Initializing...", id=f"status_{self.provider_name}", classes="status-indicator initializing")

        # Metrics section
        with Vertical(classes="metrics-section"):
            yield Label("Port: -", id=f"port_{self.provider_name}", classes="metric")
            yield Label("Models: -", id=f"models_{self.provider_name}", classes="metric")
            yield Label("VRAM: -", id=f"vram_{self.provider_name}", classes="metric vram-low")
            yield Label("Resp: -", id=f"response_{self.provider_name}", classes="metric")

        # Action buttons
        with Horizontal(classes="actions-section"):
            yield Button("Start", id=f"start_{self.provider_name}", variant="success", classes="action-btn")
            yield Button("Stop", id=f"stop_{self.provider_name}", variant="error", classes="action-btn")
            yield Button("Restart", id=f"restart_{self.provider_name}", variant="warning", classes="action-btn")
            yield Button("Enable", id=f"enable_{self.provider_name}", variant="primary", classes="action-btn")
            yield Button("Disable", id=f"disable_{self.provider_name}", variant="error", classes="action-btn")


class SystemMetrics(Static):
    """Display system metrics."""

    cpu_percent = reactive(0.0)
    memory_percent = reactive(0.0)

    def on_mount(self) -> None:
        self.set_interval(2.0, self.update_metrics)

    def update_metrics(self):
        """Update system metrics."""
        self.cpu_percent = psutil.cpu_percent(interval=None)
        self.memory_percent = psutil.virtual_memory().percent

    def watch_cpu_percent(self, cpu: float):
        """Update when CPU changes."""
        try:
            cpu_widget = self.query_one("#cpu_label")
            cpu_widget.update(f"CPU: {cpu:.1f}%")
            cpu_widget.remove_class("low", "medium", "high")
            if cpu > 80:
                cpu_widget.add_class("high")
            elif cpu > 50:
                cpu_widget.add_class("medium")
            else:
                cpu_widget.add_class("low")
        except:
            pass

    def watch_memory_percent(self, memory: float):
        """Update when memory changes."""
        try:
            mem_widget = self.query_one("#memory_label")
            mem_widget.update(f"MEM: {memory:.1f}%")
            mem_widget.remove_class("low", "medium", "high")
            if memory > 80:
                mem_widget.add_class("high")
            elif memory > 50:
                mem_widget.add_class("medium")
            else:
                mem_widget.add_class("low")
        except:
            pass

    def compose(self) -> ComposeResult:
        with Horizontal(classes="system-metrics"):
            yield Label("CPU: 0.0%", id="cpu_label", classes="metric low")
            yield Label("MEM: 0.0%", id="memory_label", classes="metric low")


class AIDashboard(App):
    """Consolidated AI Backend Dashboard."""

    CSS = """
    Screen {
        layout: grid;
        grid-size: 3;
        grid-columns: 1fr 1fr 1fr;
        grid-rows: auto 1fr auto;
        grid-gutter: 1;
        background: $surface;
    }

    Header {
        height: 1;
        background: $primary;
        color: $text;
        text-style: bold;
        column-span: 3;
    }

    Footer {
        height: 1;
        background: $primary;
        color: $text;
        column-span: 3;
    }

    #providers-panel {
        column-span: 2;
        border: solid $primary;
        padding: 1;
        height: 1fr;
    }

    #gpu-panel {
        border: solid $secondary;
        padding: 1;
        height: 1fr;
    }

    #metrics-panel {
        column-span: 3;
        border: solid $accent;
        padding: 1;
        height: auto;
    }

    .panel-title {
        text-style: bold;
        margin-bottom: 1;
        color: $primary;
    }

    .card-header {
        height: auto;
        margin-bottom: 1;
    }

    .provider-name {
        width: 20;
        text-style: bold;
        background: $boost;
        text-align: center;
    }

    .status-indicator {
        width: 15;
        text-align: center;
        text-style: bold;
    }

    .status-indicator.active {
        color: $success;
    }

    .status-indicator.inactive {
        color: $warning;
    }

    .status-indicator.error {
        color: $error;
    }

    .status-indicator.initializing {
        color: $text-disabled;
    }

    .metrics-section {
        height: auto;
        margin-bottom: 1;
    }

    .metric {
        width: 100%;
        height: 1;
        margin: 0 0 1 0;
        background: $boost;
        padding: 0 1;
    }

    .metric.vram-low {
        color: $success;
    }

    .metric.vram-medium {
        color: $warning;
    }

    .metric.vram-high {
        color: $error;
    }

    .actions-section {
        height: auto;
        align: center middle;
        overflow-x: auto;
    }

    .action-btn {
        width: 8;
        height: 1;
        margin: 0 1;
        min-width: 8;
    }

    .gpu-info {
        margin: 0 0 1 0;
        background: $boost;
        padding: 0 1;
    }

    .system-metrics {
        margin: 1 0;
        height: auto;
        align: center middle;
    }

    ProgressBar {
        height: 1;
        margin: 0 0 1 0;
    }

    .metric.low {
        color: $success;
    }

    .metric.medium {
        color: $warning;
    }

    .metric.high {
        color: $error;
    }
    """

    BINDINGS = [
        Binding("r", "refresh", "Refresh"),
        Binding("q", "quit", "Quit"),
        Binding("ctrl+d", "toggle_dark", "Toggle Dark Mode"),
        Binding("f1", "show_help", "Help"),
        Binding("1", "view_basic", "Basic View"),
        Binding("2", "view_enhanced", "Enhanced View"),
        Binding("3", "view_unified", "Unified View"),
    ]

    def __init__(self):
        super().__init__()
        self.provider_monitor = ProviderMonitor()
        self.gpu_monitor = GPUMonitor()

    def compose(self) -> ComposeResult:
        """Create the dashboard UI."""
        yield Header("AI Backend Consolidated Dashboard")

        # Providers panel (spans 2 columns)
        with Vertical(id="providers-panel"):
            yield Label("[b]AI Providers Status[/b]", classes="panel-title")
            yield ProviderCard("ollama")
            yield ProviderCard("vllm-qwen")
            yield ProviderCard("vllm-dolphin")
            yield ProviderCard("llama_cpp_python")
            yield ProviderCard("llama_cpp_native")

        # GPU panel (right column)
        with Vertical(id="gpu-panel"):
            yield Label("[b]GPU Resources[/b]", classes="panel-title")
            yield Label("Loading GPU information...", id="gpu-info", classes="gpu-info")
            yield ProgressBar(id="gpu-memory-bar", total=100, show_eta=False)
            yield Label("GPU Utilization: -%", id="gpu-util", classes="metric")

        # System metrics panel (bottom, spans all columns)
        with Vertical(id="metrics-panel"):
            yield Label("[b]System Metrics[/b]", classes="panel-title")
            yield SystemMetrics()

        yield Footer()

    def on_mount(self) -> None:
        """Start auto-refresh when app mounts."""
        self.refresh_data()
        self.set_interval(5.0, self.refresh_data)
        self.set_interval(2.0, self.update_gpu_info)

    def refresh_data(self):
        """Refresh all provider data."""
        self.refresh_providers()
        self.update_gpu_info()

    def refresh_providers(self):
        """Refresh provider data."""
        statuses = self.provider_monitor.get_all_provider_status()

        for status in statuses:
            # Update status for each provider card
            try:
                for card in self.query(ProviderCard).results():
                    if card.provider_name == status.name:
                        # Update status indicator
                        status_widget = card.query_one(f"#status_{status.name}")
                        status_text = f"● {status.status.title()}"
                        status_widget.update(status_text)

                        # Clear all status classes and add current one
                        for cls in ["initializing", "active", "inactive", "error"]:
                            status_widget.remove_class(cls)
                        status_widget.add_class(status.status.lower())

                        # Update metrics
                        card.query_one(f"#port_{status.name}").update(f"Port: {status.port}")
                        card.query_one(f"#models_{status.name}").update(f"Models: {status.model_count}")

                        # Update VRAM if available
                        if status.vram_usage_mb > 0:
                            vram_widget = card.query_one(f"#vram_{status.name}")
                            vram_widget.update(f"VRAM: {status.vram_usage_mb:.0f}MB ({status.vram_percentage:.1f}%)")

                            # Add VRAM usage coloring
                            vram_widget.remove_class("vram-low", "vram-medium", "vram-high")
                            if status.vram_percentage > 80:
                                vram_widget.add_class("vram-high")
                            elif status.vram_percentage > 50:
                                vram_widget.add_class("vram-medium")
                            else:
                                vram_widget.add_class("vram-low")
                        else:
                            card.query_one(f"#vram_{status.name}").update("VRAM: -")

                        # Update response time
                        response_time = f"{status.response_time}ms" if status.response_time > 0 else "-"
                        card.query_one(f"#response_{status.name}").update(f"Resp: {response_time}")
                        break
            except:
                continue

    def update_gpu_info(self):
        """Update GPU information."""
        if not self.gpu_monitor.initialized:
            try:
                self.query_one("#gpu-info").update("No NVIDIA GPU detected")
                self.query_one("#gpu-memory-bar").progress = 0
                self.query_one("#gpu-util").update("GPU Utilization: -%")
            except:
                pass
            return

        try:
            gpus = self.gpu_monitor.get_gpu_info()
            if gpus:
                gpu = gpus[0]  # For simplicity, show first GPU
                info_text = f"{gpu['name']} | {gpu['memory_used_mb']:.0f}/{gpu['memory_total_mb']:.0f}MB"

                self.query_one("#gpu-info").update(info_text)
                memory_bar = self.query_one("#gpu-memory-bar")
                memory_bar.total = 100
                memory_bar.progress = gpu['memory_util_percent']

                util_widget = self.query_one("#gpu-util")
                util_widget.update(f"GPU Utilization: {gpu['gpu_util_percent']:.1f}%")

                # Add coloring based on usage
                util_widget.remove_class("low", "medium", "high")
                if gpu['gpu_util_percent'] > 80:
                    util_widget.add_class("high")
                elif gpu['gpu_util_percent'] > 50:
                    util_widget.add_class("medium")
                else:
                    util_widget.add_class("low")
        except:
            pass

    def on_button_pressed(self, event: Button.Pressed) -> None:
        """Handle button presses."""
        button_id = event.button.id

        # Handle Start/Stop/Restart commands
        action_map = {
            "start_": "start",
            "stop_": "stop",
            "restart_": "restart",
            "enable_": "enable",
            "disable_": "disable"
        }

        for prefix, action in action_map.items():
            if button_id.startswith(prefix):
                provider = button_id.replace(prefix, "")
                service_map = {
                    "ollama": "ollama.service",
                    "vllm-qwen": "vllm.service",
                    "vllm-dolphin": "vllm-dolphin.service",
                    "llama_cpp_python": "llamacpp-python.service",
                    "llama_cpp_native": "llama-cpp-native.service"
                }

                service_name = service_map.get(provider)
                if service_name:
                    self.notify(f"{action.capitalize()}ing {provider}...")
                    success = self.provider_monitor.systemctl_command(action, service_name)
                    if success:
                        self.notify(f"{provider} {action}ed successfully!")
                    else:
                        self.notify(f"Failed to {action} {provider}!", severity="error")
                break

    def action_refresh(self) -> None:
        """Refresh all data."""
        self.refresh_data()
        self.notify("Dashboard refreshed!")

    def action_show_help(self) -> None:
        """Show help information."""
        self.notify("AI Backend Consolidated Dashboard\n\n"
                   "R - Refresh all data\n"
                   "Q - Quit application\n"
                   "Ctrl+D - Toggle dark mode\n"
                   "F1 - Show this help\n"
                   "1 - Basic view\n"
                   "2 - Enhanced view\n"
                   "3 - Unified view\n\n"
                   "Provider Controls:\n"
                   "• Start/Stop: Runtime control\n"
                   "• Restart: Restart service\n"
                   "• Enable/Disable: Autostart control\n\n"
                   "Shows real-time provider status and VRAM usage")

    def action_view_basic(self) -> None:
        """Switch to basic view."""
        self.notify("Switching to basic view...")
        # Simple view - hide some detailed metrics

    def action_view_enhanced(self) -> None:
        """Switch to enhanced view."""
        self.notify("Switching to enhanced view...")
        # Enhanced view - show all metrics

    def action_view_unified(self) -> None:
        """Switch to unified view."""
        self.notify("Switching to unified view...")
        # Unified view - show everything


if __name__ == "__main__":
    app = AIDashboard()
    app.run()
