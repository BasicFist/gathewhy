# ============================================================================
# AUTO-GENERATED FILE - DO NOT EDIT MANUALLY
# ============================================================================
#
# Generated by: scripts/simple-generate-config.py
# Source files: config/providers.yaml, config/model-mappings.yaml
# Generated at: 2025-11-09T07:06:32.386993
#
# To modify this configuration:
#   1. Edit config/providers.yaml or config/model-mappings.yaml
#   2. Run: python3 scripts/simple-generate-config.py
#
# ============================================================================

model_list:
  - model_name: llama3.1:latest
    litellm_params:
      model: ollama/llama3.1:latest
      api_base: http://127.0.0.1:11434
    model_info:
      tags:
        - general_chat
        - 8b
        - q4_k_m
      provider: ollama
  - model_name: qwen2.5-coder:7b
    litellm_params:
      model: ollama/qwen2.5-coder:7b
      api_base: http://127.0.0.1:11434
    model_info:
      tags:
        - code_generation
        - 7.6b
        - q4_k_m
      provider: ollama
  - model_name: mythomax-l2-13b-q5_k_m
    litellm_params:
      model: ollama/mythomax-l2-13b-q5_k_m
      api_base: http://127.0.0.1:11434
      extra_body:
        options:
          num_gpu_layers: -1
    model_info:
      tags:
        - creative_writing
        - 13b
        - q5_k_m
      provider: ollama
  - model_name: Qwen/Qwen2.5-Coder-7B-Instruct-AWQ
    litellm_params:
      model: Qwen/Qwen2.5-Coder-7B-Instruct-AWQ
      api_base: http://127.0.0.1:8001/v1
      custom_llm_provider: openai
      stream: true
      api_key: not-needed
    model_info:
      tags:
        - code_generation
        - 7b
        - awq
      provider: vllm-qwen
      context_length: 4096
  - model_name: deepseek-v3.1:671b-cloud
    litellm_params:
      model: ollama_chat/deepseek-v3.1:671b-cloud
      api_base: https://ollama.com
      api_key: os.environ/OLLAMA_API_KEY
    model_info:
      tags:
        - advanced_reasoning
        - 671b
      provider: ollama_cloud
  - model_name: qwen3-coder:480b-cloud
    litellm_params:
      model: ollama_chat/qwen3-coder:480b-cloud
      api_base: https://ollama.com
      api_key: os.environ/OLLAMA_API_KEY
    model_info:
      tags:
        - code_generation
        - 480b
      provider: ollama_cloud
  - model_name: kimi-k2:1t-cloud
    litellm_params:
      model: ollama_chat/kimi-k2:1t-cloud
      api_base: https://ollama.com
      api_key: os.environ/OLLAMA_API_KEY
    model_info:
      tags:
        - advanced_reasoning
        - 1t
      provider: ollama_cloud
  - model_name: gpt-oss:120b-cloud
    litellm_params:
      model: ollama_chat/gpt-oss:120b-cloud
      api_base: https://ollama.com
      api_key: os.environ/OLLAMA_API_KEY
    model_info:
      tags:
        - general_chat
        - 120b
      provider: ollama_cloud
  - model_name: gpt-oss:20b-cloud
    litellm_params:
      model: ollama_chat/gpt-oss:20b-cloud
      api_base: https://ollama.com
      api_key: os.environ/OLLAMA_API_KEY
    model_info:
      tags:
        - general_chat
        - 20b
      provider: ollama_cloud
  - model_name: glm-4.6:cloud
    litellm_params:
      model: ollama_chat/glm-4.6:cloud
      api_base: https://ollama.com
      api_key: os.environ/OLLAMA_API_KEY
    model_info:
      tags:
        - general_chat
        - 4.6b
      provider: ollama_cloud
  - model_name: gpt-4o
    litellm_params:
      model: gpt-4o
      api_key: os.environ/OPENAI_API_KEY
    model_info:
      tags:
        - advanced_reasoning
        - unknown
      provider: openai
      context_length: 128000
  - model_name: gpt-4o-mini
    litellm_params:
      model: gpt-4o-mini
      api_key: os.environ/OPENAI_API_KEY
    model_info:
      tags:
        - general_chat
        - unknown
      provider: openai
      context_length: 128000
  - model_name: gpt-4-turbo
    litellm_params:
      model: gpt-4-turbo
      api_key: os.environ/OPENAI_API_KEY
    model_info:
      tags:
        - advanced_reasoning
        - unknown
      provider: openai
      context_length: 128000
  - model_name: gpt-4
    litellm_params:
      model: gpt-4
      api_key: os.environ/OPENAI_API_KEY
    model_info:
      tags:
        - advanced_reasoning
        - unknown
      provider: openai
      context_length: 8192
  - model_name: gpt-3.5-turbo
    litellm_params:
      model: gpt-3.5-turbo
      api_key: os.environ/OPENAI_API_KEY
    model_info:
      tags:
        - general_chat
        - unknown
      provider: openai
      context_length: 16385
  - model_name: o1
    litellm_params:
      model: o1
      api_key: os.environ/OPENAI_API_KEY
    model_info:
      tags:
        - advanced_reasoning
        - unknown
      provider: openai
      context_length: 200000
  - model_name: o1-mini
    litellm_params:
      model: o1-mini
      api_key: os.environ/OPENAI_API_KEY
    model_info:
      tags:
        - code_generation
        - unknown
      provider: openai
      context_length: 128000
  - model_name: claude-3-5-sonnet-20241022
    litellm_params:
      model: claude-3-5-sonnet-20241022
      api_key: os.environ/ANTHROPIC_API_KEY
    model_info:
      tags:
        - advanced_reasoning
        - unknown
      provider: anthropic
      context_length: 200000
  - model_name: claude-3-5-haiku-20241022
    litellm_params:
      model: claude-3-5-haiku-20241022
      api_key: os.environ/ANTHROPIC_API_KEY
    model_info:
      tags:
        - general_chat
        - unknown
      provider: anthropic
      context_length: 200000
  - model_name: claude-3-opus-20240229
    litellm_params:
      model: claude-3-opus-20240229
      api_key: os.environ/ANTHROPIC_API_KEY
    model_info:
      tags:
        - advanced_reasoning
        - unknown
      provider: anthropic
      context_length: 200000
  - model_name: claude-3-sonnet-20240229
    litellm_params:
      model: claude-3-sonnet-20240229
      api_key: os.environ/ANTHROPIC_API_KEY
    model_info:
      tags:
        - general_chat
        - unknown
      provider: anthropic
      context_length: 200000
  - model_name: claude-3-haiku-20240307
    litellm_params:
      model: claude-3-haiku-20240307
      api_key: os.environ/ANTHROPIC_API_KEY
    model_info:
      tags:
        - general_chat
        - unknown
      provider: anthropic
      context_length: 200000
litellm_settings:
  request_timeout: 60
  stream_timeout: 120
  num_retries: 3
  timeout: 300
  cache: true
  cache_params:
    type: redis
    host: 127.0.0.1
    port: 6379
    ttl: 3600
  set_verbose: true
  json_logs: true
router_settings:
  routing_strategy: simple-shuffle
  allowed_fails: 5
  num_retries: 2
  timeout: 30
  cooldown_time: 60
  enable_pre_call_checks: true
  redis_host: 127.0.0.1
  redis_port: 6379
  model_group_alias:
    code_generation:
      - o1-mini
    analysis:
      - claude-3-5-sonnet-20241022
    reasoning:
      - o1
    creative_writing:
      - claude-3-opus-20240229
    conversational:
      - gpt-4o-mini
    vision:
      - gpt-4o
    function_calling:
      - gpt-4o
    extended_context:
      - claude-3-5-sonnet-20241022
    general_chat:
      - llama3.1:latest
