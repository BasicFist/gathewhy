# Web UI Configuration

server:
  host: "0.0.0.0"
  port: 5001
  share: false  # Set true for public Gradio link

litellm:
  base_url: "http://localhost:4000"
  api_key: "not-needed"  # pragma: allowlist secret
  timeout: 120

ui:
  title: "AI Backend - Model Testing Interface"
  description: "Interactive testing and comparison for LiteLLM unified backend"
  theme: "soft"  # soft, default, monochrome
  max_chat_history: 50

comparison:
  max_models: 4
  min_models: 2
  show_timing: true
  show_tokens: true

parameters:
  temperature:
    min: 0.0
    max: 2.0
    default: 0.7
    step: 0.1

  max_tokens:
    min: 1
    max: 4096
    default: 512
    step: 1

  top_p:
    min: 0.0
    max: 1.0
    default: 0.9
    step: 0.05

database:
  path: "web-ui/requests.db"
  enable_analytics: true
  retention_days: 30
